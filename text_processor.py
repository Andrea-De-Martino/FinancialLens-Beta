# text_processor.py - FIXED VERSION

import re
import logging
from fuzzywuzzy import process, fuzz
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass


@dataclass
class MatchCandidate:
    """A potential match with metadata."""
    canonical_name: str
    score: int
    synonym_matched: str
    context: str


@dataclass
class DisambiguationContext:
    """Context for disambiguating matches."""
    current_parent: Optional[str]
    current_branch: Optional[str]
    parent_stack: List[Any]  # Changed from List[Dict[str, Any]] to List[Any] to handle both dicts and FinancialItem objects


class TextProcessor:
    """
    Handles text normalization, fuzzy matching, and disambiguation logic.
    
    This module encapsulates the sophisticated text processing capabilities
    that form the core of the financial statement parsing system. It manages
    the complex process of matching raw PDF text against the structured
    financial statement schema using advanced fuzzy string matching techniques.
    
    The processor implements a multi-stage matching strategy:
    1. Text normalization to standardize input for consistent matching
    2. Fuzzy matching against synonym dictionaries to find potential candidates
    3. Context-aware disambiguation to resolve ambiguous matches
    4. Ignore pattern filtering to skip irrelevant text
    
    The disambiguation logic is particularly sophisticated, using hierarchical
    context from the parent stack to prefer matches that make sense within
    the current financial statement structure. This prevents incorrect matches
    that could occur from purely score-based selection.
    
    All matching thresholds and algorithms are preserved exactly from the
    original implementation to ensure identical parsing behavior and maintain
    the carefully tuned balance between precision and recall.
    """

    def __init__(self, config: Dict[str, Any]):
        """
        Initialize text processor with matching configuration.
        
        Args:
            config: Configuration containing thresholds, mappings, and patterns
        """
        self.fuzzy_score_threshold = config.get('fuzzy_score_threshold', 90)
        self.ignore_fuzzy_score_threshold = config.get('ignore_fuzzy_score_threshold', 90)
        
        # Contextual mappings generated by configuration manager
        self.inverted_configs = config.get('inverted_configs', {})
        self.parent_map = config.get('parent_map', {})
        self.branch_map = config.get('branch_map', {})
        
        # Processed ignore patterns
        self.ignore_patterns = config.get('ignore_patterns', [])

    def normalize_text(self, text: Any, for_matching: bool = False) -> str:
        """
        Normalize text using exact same logic as original parser.
        
        This method preserves the exact text normalization behavior from the
        original _normalize_text method. The normalization process is critical
        for consistent matching behavior, as it standardizes the text format
        to handle variations in whitespace, capitalization, and special characters.
        
        The for_matching parameter triggers additional aggressive normalization
        that removes all non-alphanumeric characters except spaces, which is
        essential for fuzzy matching to work effectively with financial text
        that often contains punctuation and formatting characters.
        
        Args:
            text: Input text to normalize (can be any type, will be converted to string)
            for_matching: Whether to apply aggressive normalization for fuzzy matching
            
        Returns:
            Normalized text string ready for processing or matching
        """
        if not text:
            return ""
        
        # Convert to string and apply basic cleanup exactly as original
        text_str = str(text).strip().lower()
        
        # Replace tabs and carriage returns with spaces
        text_str = re.sub(r'[\t\r]', ' ', text_str)
        
        if for_matching:
            # Additional normalization for fuzzy matching
            text_str = text_str.replace('\n', ' ')
            text_str = re.sub(r'[^a-z0-9\s]', '', text_str)
        
        # Final cleanup: normalize multiple spaces to single space
        return re.sub(r'\s+', ' ', text_str.strip())

    def find_best_matches(self, text: str, context: str) -> List[MatchCandidate]:
        """
        Find potential matches using fuzzy matching.
        
        This method replicates the exact _find_best_matches logic from the
        original parser, including the same fuzzy matching algorithm, threshold
        handling, and candidate generation process. It uses the sophisticated
        inverted configuration mappings to find potential canonical names
        that could match the input text.
        
        The method employs a two-stage process: first finding the best matching
        synonyms using fuzzy string matching, then expanding those matches to
        their corresponding canonical names. This allows for flexible matching
        while maintaining the structured relationship to the financial schema.
        
        Args:
            text: Raw text from PDF to match against schema
            context: Financial statement context ('stato_patrimoniale' or 'conto_economico')
            
        Returns:
            List of potential matches with confidence scores, sorted by score descending
        """
        # Normalize input text for matching exactly as original
        norm_text = self.normalize_text(text, for_matching=True)
        context_map = self.inverted_configs.get(context, {})
        
        if not norm_text or not context_map:
            return []
        
        # Find best matching synonyms using exact same fuzzy algorithm
        best_matching_synonyms = process.extract(norm_text, context_map.keys(), limit=5)
        
        all_candidates = []
        for match_text, score in best_matching_synonyms:
            # Apply same threshold filtering as original
            if score < self.fuzzy_score_threshold - 10:
                continue
            
            # Expand synonym matches to canonical names
            canonical_names = context_map.get(match_text, [])
            for canonical_name in canonical_names:
                all_candidates.append(MatchCandidate(
                    canonical_name=canonical_name,
                    score=int(score),
                    synonym_matched=match_text,
                    context=context
                ))
        
        # Deduplicate and sort exactly as original
        unique_candidates = {}
        for candidate in all_candidates:
            key = candidate.canonical_name
            if key not in unique_candidates or candidate.score > unique_candidates[key].score:
                unique_candidates[key] = candidate
        
        return sorted(unique_candidates.values(), key=lambda x: x.score, reverse=True)

    def disambiguate_candidates(self, candidates: List[MatchCandidate], 
                               context: DisambiguationContext) -> Tuple[str, int]:
        """
        Resolve ambiguous matches using context.
        
        This method preserves the exact disambiguation logic from the original
        _disambiguate_candidates method. It implements a sophisticated context-aware
        strategy that considers the hierarchical position within the financial
        statement structure to resolve ambiguous matches.
        
        The disambiguation process follows a specific priority order:
        1. Single candidate - return immediately
        2. Score proximity filtering - consider only candidates within score range  
        3. Branch context preference - favor matches in same branch (attivo/passivo)
        4. Parent relationship preference - favor direct children of current parent
        5. Fallback to highest scoring candidate
        
        This context-sensitive approach prevents incorrect matches that could
        result from purely score-based selection, particularly important for
        financial statements where similar terms appear in different contexts.
        
        Args:
            candidates: List of potential matches to disambiguate
            context: Current parsing context including parent stack information
            
        Returns:
            Tuple of (best match canonical name, confidence score)
        """
        if not candidates:
            return "", 0
        
        if len(candidates) == 1:
            return candidates[0].canonical_name, candidates[0].score

        # Filter candidates by score proximity exactly as original
        best_score = candidates[0].score
        top_candidates = [c for c in candidates if c.score >= best_score - 5]

        if len(top_candidates) == 1:
            return top_candidates[0].canonical_name, top_candidates[0].score

        # Apply context-based disambiguation if parent stack exists
        if context.parent_stack:
            current_parent_name = context.current_parent
            current_branch = self.branch_map.get(current_parent_name)

            # Prefer candidates in same branch as current parent
            if current_branch:
                branch_candidates = [
                    cand for cand in top_candidates 
                    if self.branch_map.get(cand.canonical_name) == current_branch
                ]
                if branch_candidates:
                    top_candidates = branch_candidates
                elif logging.getLogger().isEnabledFor(logging.DEBUG):
                    logging.debug(
                        f"No candidates in branch '{current_branch}' for parent '{current_parent_name}'. "
                        f"Possible section change."
                    )

            if len(top_candidates) == 1:
                return top_candidates[0].canonical_name, top_candidates[0].score

            # Prefer direct children of current parent
            direct_children = [
                cand for cand in top_candidates 
                if self.parent_map.get(cand.canonical_name) == current_parent_name
            ]
            if direct_children:
                logging.debug(
                    f"Chose '{direct_children[0].canonical_name}' as direct child of '{current_parent_name}'"
                )
                return direct_children[0].canonical_name, direct_children[0].score

        # Fallback to highest scoring candidate
        return top_candidates[0].canonical_name, top_candidates[0].score

    def is_ignorable_text(self, text: str) -> bool:
        """
        Check if text should be ignored using exact same logic as original.
        
        This method preserves the _is_ignorable behavior from the original parser,
        including the same fuzzy matching against ignore patterns and threshold
        evaluation. The ignore functionality is crucial for filtering out
        irrelevant text like totals, subtotals, and formatting elements that
        appear in financial statements but shouldn't be processed as line items.
        
        The method uses fuzzy matching to handle variations in ignore patterns,
        allowing it to catch similar but not identical text that should be skipped.
        This flexibility is important for handling diverse PDF formatting while
        maintaining precise control over what gets processed.
        
        Args:
            text: Text to check for ignore patterns
            
        Returns:
            True if text should be ignored, False if it should be processed
        """
        # Normalize text for matching exactly as original
        norm_text = self.normalize_text(text, for_matching=True)
        
        if not norm_text:
            return True
        
        # Check against ignore patterns using fuzzy matching
        best_match = process.extractOne(norm_text, self.ignore_patterns)
        
        return bool(best_match and best_match[1] >= self.ignore_fuzzy_score_threshold)

    def create_disambiguation_context(self, parent_stack: List[Any]) -> DisambiguationContext:
        """
        Create disambiguation context from parent stack.
        
        Helper method to create structured disambiguation context from the
        current parent stack state. This method now handles both dictionary
        objects (from original parser) and FinancialItem objects (from refactored parser).
        
        Args:
            parent_stack: Current hierarchy parent stack (can contain dicts or FinancialItem objects)
            
        Returns:
            Structured disambiguation context
        """
        current_parent = None
        current_branch = None
        
        if parent_stack:
            last_item = parent_stack[-1]
            
            # Handle both dictionary and FinancialItem objects
            if hasattr(last_item, 'voce_canonica'):
                # FinancialItem object - access as attribute
                current_parent = last_item.voce_canonica
            elif isinstance(last_item, dict):
                # Dictionary object - access as key
                current_parent = last_item.get('voce_canonica')
            
            if current_parent:
                current_branch = self.branch_map.get(current_parent)
        
        return DisambiguationContext(
            current_parent=current_parent,
            current_branch=current_branch,
            parent_stack=parent_stack
        )

    def get_fuzzy_score_threshold(self) -> int:
        """
        Get the current fuzzy score threshold.
        
        Returns:
            Configured fuzzy matching threshold
        """
        return self.fuzzy_score_threshold

    def get_ignore_threshold(self) -> int:
        """
        Get the current ignore pattern threshold.
        
        Returns:
            Configured ignore pattern matching threshold
        """
        return self.ignore_fuzzy_score_threshold

    def get_available_contexts(self) -> List[str]:
        """
        Get list of available matching contexts.
        
        Returns:
            List of context names that can be used for matching
        """
        return list(self.inverted_configs.keys())

    def get_context_statistics(self, context: str) -> Dict[str, int]:
        """
        Get statistics about a matching context.
        
        Provides information about the number of synonyms and canonical
        names available for matching in a given context.
        
        Args:
            context: Context name to analyze
            
        Returns:
            Dictionary with context statistics
        """
        context_map = self.inverted_configs.get(context, {})
        
        synonym_count = len(context_map)
        canonical_count = len(set(
            canonical for synonym_list in context_map.values() 
            for canonical in synonym_list
        ))
        
        return {
            'synonym_count': synonym_count,
            'canonical_count': canonical_count,
            'context': context
        }

    def validate_configuration(self) -> bool:
        """
        Validate that text processor configuration is complete.
        
        Ensures that all required configuration elements are present
        and properly structured for text processing operations.
        
        Returns:
            True if configuration is valid, False otherwise
        """
        required_configs = ['inverted_configs', 'parent_map', 'branch_map']
        
        for config_name in required_configs:
            if not hasattr(self, config_name) or not getattr(self, config_name):
                logging.error(f"Missing or empty required configuration: {config_name}")
                return False
        
        # Validate that we have contexts for major financial statement sections
        expected_contexts = ['stato_patrimoniale', 'conto_economico']
        missing_contexts = [ctx for ctx in expected_contexts if ctx not in self.inverted_configs]
        
        if missing_contexts:
            logging.error(f"Missing expected contexts: {missing_contexts}")
            return False
        
        return True